name: Fetch YouTube Metadata

on:
  # Manual trigger
  workflow_dispatch:
    inputs:
      channel:
        description: 'Single channel to fetch (leave empty to use config)'
        required: false
        type: string
      backfill:
        description: 'Run full backfill (ignore incremental)'
        required: false
        type: boolean
        default: false
      skip_comments:
        description: 'Skip fetching comments'
        required: false
        type: boolean
        default: false
      skip_transcripts:
        description: 'Skip fetching transcripts'
        required: false
        type: boolean
        default: false
  
  # Scheduled runs - 4 times daily
  schedule:
    - cron: '0 0 * * *'   # Midnight UTC
    - cron: '0 6 * * *'   # 6 AM UTC
    - cron: '0 12 * * *'  # Noon UTC
    - cron: '0 18 * * *'  # 6 PM UTC

env:
  PYTHON_VERSION: '3.11'

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    # Prevent concurrent runs to avoid database conflicts
    concurrency:
      group: youtube-fetch
      cancel-in-progress: false
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download existing database
        uses: actions/download-artifact@v4
        with:
          name: youtube-database
          path: data/
        continue-on-error: true  # OK if no previous database

      - name: Ensure config exists
        run: |
          if [ ! -f "config/channels.yaml" ]; then
            if [ -f "config/channels.example.yaml" ]; then
              cp config/channels.example.yaml config/channels.yaml
              echo "Using example config"
            else
              echo "No config file found!"
              exit 1
            fi
          fi

      - name: Fetch YouTube data
        id: fetch
        env:
          YOUTUBE_API_KEY: ${{ secrets.YOUTUBE_API_KEY }}
        run: |
          cd scripts
          
          # Build command
          if [ -n "${{ github.event.inputs.channel }}" ]; then
            CMD="python fetch.py --channel '${{ github.event.inputs.channel }}'"
          else
            CMD="python fetch.py --config ../config/channels.yaml"
          fi
          
          # Add flags
          if [ "${{ github.event.inputs.backfill }}" == "true" ]; then
            CMD="$CMD --backfill"
          fi
          
          if [ "${{ github.event.inputs.skip_comments }}" == "true" ]; then
            CMD="$CMD --skip-comments"
          fi
          
          if [ "${{ github.event.inputs.skip_transcripts }}" == "true" ]; then
            CMD="$CMD --skip-transcripts"
          fi
          
          echo "Running: $CMD"
          eval $CMD

      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        with:
          name: youtube-database
          path: data/youtube.duckdb
          retention-days: 90
          overwrite: true

      - name: Generate summary report
        run: |
          cd scripts
          
          echo "## YouTube Fetch Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run time:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Summary stats
          echo "### Database Summary" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          python analyze.py --report summary >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Channels
          echo "### Tracked Channels" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          python analyze.py --report channels >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Recent fetch history
          echo "### Recent Fetches" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          python analyze.py --sql "SELECT * FROM fetch_log ORDER BY started_at DESC LIMIT 5" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY

  # Weekly export to Parquet
  export:
    runs-on: ubuntu-latest
    needs: fetch
    if: github.event.schedule == '0 0 * * 0'  # Only on Sunday midnight
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download database
        uses: actions/download-artifact@v4
        with:
          name: youtube-database
          path: data/

      - name: Export to Parquet
        run: |
          cd scripts
          python fetch.py --export

      - name: Upload Parquet export
        uses: actions/upload-artifact@v4
        with:
          name: youtube-parquet-export-${{ github.run_number }}
          path: exports/
          retention-days: 30